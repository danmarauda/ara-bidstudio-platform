{
  "goal": "Visual LLM validation workflow: search for test images, analyze with GPT-5-mini and Gemini 2.0 Flash, compare results, and recommend best model",
  "type": "orchestrate",
  "topic": "Visual LLM Model Validation for VR Avatar Quality Assessment (GPT-5-mini vs Gemini)",
  "graph": {
    "nodes": [
      {
        "id": "image_search",
        "kind": "search",
        "label": "Search VR Avatar Test Images",
        "prompt": "Find high-quality images of VR avatars, virtual reality characters, 3D avatars with various poses, movements, and clothing. Focus on full-body avatars showing hands, feet, eyes, and clothing details."
      },
      {
        "id": "dataset_prep",
        "kind": "structured",
        "label": "Prepare Image Dataset",
        "prompt": "Extract image URLs from search results: {{channel:image_search.last}}. Create a structured dataset with imageId, url, source, and description for each image. Limit to 10 most relevant images. Return JSON array with schema: [{imageId: string, url: string, source: string, description: string}]"
      },
      {
        "id": "gpt5mini_vision",
        "kind": "structured",
        "label": "GPT-5-mini Vision Analysis",
        "prompt": "Analyze these VR avatar images for quality issues. For EACH image in the dataset, detect: 1) Visual artifacts (redlines, distortions, glitches), 2) Movement quality issues (frozen feet, static fingers), 3) Eye rendering problems (red lines, artifacts), 4) Clothing distortions. Rate on 1-5 scale: movementMotion, visualQuality, emotionalComfort (1=worst/distorted, 5=best/no artifacts). Provide confidence score 0-1. Return JSON array with schema: [{imageId: string, modelName: 'gpt-5-mini', artifacts: {hasRedlines: boolean, hasDistortions: boolean, distortionLocations: string[]}, ratings: {movementMotion: number, visualQuality: number, emotionalComfort: number}, specificIssues: {feetMovement: boolean, fingerMovement: boolean, eyeArtifacts: boolean, clothingDistortions: boolean}, confidence: number, detailedFindings: string}]. Images: {{channel:dataset_prep.last}}"
      },
      {
        "id": "gemini_vision",
        "kind": "structured",
        "label": "Gemini 2.0 Flash Vision Analysis",
        "prompt": "Analyze these VR avatar images for quality issues. For EACH image in the dataset, detect: 1) Visual artifacts (redlines, distortions, glitches), 2) Movement quality issues (frozen feet, static fingers), 3) Eye rendering problems (red lines, artifacts), 4) Clothing distortions. Rate on 1-5 scale: movementMotion, visualQuality, emotionalComfort (1=worst/distorted, 5=best/no artifacts). Provide confidence score 0-1. Return JSON array with schema: [{imageId: string, modelName: 'gemini-2.5-flash', artifacts: {hasRedlines: boolean, hasDistortions: boolean, distortionLocations: string[]}, ratings: {movementMotion: number, visualQuality: number, emotionalComfort: number}, specificIssues: {feetMovement: boolean, fingerMovement: boolean, eyeArtifacts: boolean, clothingDistortions: boolean}, confidence: number, detailedFindings: string}]. Images: {{channel:dataset_prep.last}}"
      },
      {
        "id": "statistical_analysis",
        "kind": "custom",
        "label": "Statistical Analysis & Aggregation",
        "prompt": "Using Python with pandas, numpy, and scipy: 1) Combine results from GPT-5-mini: {{channel:gpt5mini_vision.last}} and Gemini: {{channel:gemini_vision.last}}. 2) Calculate inter-model agreement using Pearson correlation for each rating metric (movementMotion, visualQuality, emotionalComfort). 3) Compute mean, median, std dev for each metric per model. 4) Calculate average ratings across both models per image. 5) Identify outliers (ratings >2 std dev from mean). 6) Create 2x2 correlation matrix between models. Return results as JSON with: {agreement: {movementMotion: number, visualQuality: number, emotionalComfort: number}, averages: {gpt5mini: {...}, gemini: {...}}, outliers: [...], correlation_matrix: [[...]], summary: string}"
      },
      {
        "id": "visualization",
        "kind": "custom",
        "label": "Generate Plotly Visualizations",
        "prompt": "Using Python with plotly: Create interactive visualizations from analysis: {{channel:statistical_analysis.last}}. Generate: 1) Heatmap of model agreement (correlation matrix), 2) Box plots of rating distributions per model, 3) Bar chart comparing average ratings across models, 4) Scatter plot of confidence vs accuracy, 5) Grouped bar chart of artifact detection rates. Save plots as HTML and return summary with plot descriptions."
      },
      {
        "id": "model_comparison",
        "kind": "structured",
        "label": "Model Performance Comparison",
        "prompt": "Based on statistical analysis {{channel:statistical_analysis.last}} and visualizations {{channel:visualization.last}}, compare GPT-5-mini vs Gemini 2.0 Flash. Identify: 1) Overall best model (highest average ratings, lowest variance, best artifact detection), 2) Model rankings with scores, 3) Strengths and weaknesses of each model, 4) Task-specific recommendations (which model is best for redline detection, movement assessment, emotional comfort), 5) When to use each model, 6) Cost-effectiveness analysis. Return JSON with schema: {overallBestModel: string, modelRankings: [{modelName: string, overallScore: number, strengths: string[], weaknesses: string[]}], taskSpecificRecommendations: {redlineDetection: string, movementAssessment: string, emotionalComfort: string}, usageGuidelines: string, costEffectiveness: string}"
      },
      {
        "id": "prompt_optimization",
        "kind": "answer",
        "label": "Enhanced Prompt Generation",
        "prompt": "Based on model comparison {{channel:model_comparison.last}}, generate enhanced prompts to improve GPT-5-mini and Gemini 2.0 Flash performance. For each model, suggest: 1) Specific prompt improvements to increase artifact detection accuracy (especially redlines and distortions), 2) Additional context or examples to improve rating consistency, 3) Structured output schema refinements, 4) Model-specific optimizations (GPT-5-mini tends to be more conservative, Gemini more detailed). Provide 2 enhanced prompt templates (one for each model) with explanations of improvements and expected performance gains."
      },
      {
        "id": "eval_quality",
        "kind": "eval",
        "label": "Quality Check & Follow-up",
        "prompt": "Evaluate the completeness of the analysis. Check if: 1) All models provided structured outputs, 2) Statistical analysis completed successfully, 3) Visualizations were generated, 4) Model comparison identified clear winner. If any step failed or results are unclear, add nodes to re-run that phase with improved prompts. If quality is good, mark as complete."
      }
    ],
    "edges": [
      { "from": "image_search", "to": "dataset_prep" },
      { "from": "dataset_prep", "to": "gpt5mini_vision" },
      { "from": "dataset_prep", "to": "gemini_vision" },
      { "from": "gpt5mini_vision", "to": "statistical_analysis" },
      { "from": "gemini_vision", "to": "statistical_analysis" },
      { "from": "statistical_analysis", "to": "visualization" },
      { "from": "visualization", "to": "model_comparison" },
      { "from": "model_comparison", "to": "prompt_optimization" },
      { "from": "prompt_optimization", "to": "eval_quality" }
    ]
  },
  "constraints": {
    "maxSteps": 20
  },
  "planHints": [
    "use parallel execution for vision models",
    "use structured outputs for consistency",
    "use code execution for statistical analysis",
    "use plotly for interactive visualizations",
    "use eval nodes for quality checks"
  ],
  "notes": {
    "description": "This workflow demonstrates dual-model visual LLM validation using GPT-5-mini and Gemini 2.0 Flash. It searches for VR avatar test images, analyzes them with both vision models in parallel, performs statistical analysis and visualization, compares model performance, and generates enhanced prompts for each model.",
    "requiredEnv": [
      "OPENAI_API_KEY - for GPT-5-mini vision analysis",
      "GOOGLE_GENAI_API_KEY - for Gemini 2.0 Flash vision and code execution",
      "LINKUP_API_KEY - for image search"
    ],
    "usage": "npx tsx agents/app/cli.ts agents/app/demo_scenarios/task_spec_visual_llm_validation.json",
    "expectedDuration": "3-4 minutes",
    "estimatedCost": "$0.40-0.60 per run (10 images)",
    "outputArtifacts": [
      "Image dataset with URLs and metadata (10 VR avatar images)",
      "Structured analysis results from GPT-5-mini (JSON array)",
      "Structured analysis results from Gemini 2.0 Flash (JSON array)",
      "Statistical analysis with correlation matrices and outliers",
      "Interactive Plotly visualizations (heatmap, box plots, bar charts, scatter plots)",
      "Model comparison with rankings and task-specific recommendations",
      "Enhanced prompt templates for both models with performance improvement suggestions"
    ],
    "modelComparison": {
      "gpt5mini": {
        "strengths": ["Fast inference", "Cost-effective", "Good structured output"],
        "weaknesses": ["May be conservative in ratings", "Less detailed findings"],
        "costPerImage": "$0.015-0.025"
      },
      "gemini2flash": {
        "strengths": ["Detailed analysis", "Strong artifact detection", "Multimodal reasoning"],
        "weaknesses": ["Slightly slower", "May over-detect artifacts"],
        "costPerImage": "$0.005-0.010"
      }
    }
  }
}

